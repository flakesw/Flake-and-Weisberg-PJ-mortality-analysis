enn_high <-  unname(quantile(all_tree_vars$ENN_dist_log, .7))
}
if(quant == 0.9){
enn_low <-  unname(quantile(all_tree_vars$ENN_dist_log, 0.7))
enn_high <-  unname(quantile(all_tree_vars$ENN_dist_log, 1))
}
select_data <- which(model_frame$ENN_dist_log > enn_low & model_frame$ENN_dist_log < enn_high)
model_frame <- as.data.frame(model_frame[select_data, ])
resids <- resids[select_data]
mod_matrix <- mod_matrix[select_data, ]
ranefs <- vector(mode = "numeric", length = length(select_data))
for (i in (1:length(select_data))){
j <- select_data[i]
ranefs[i] <- ranef(model)$site[rownames(ranef(model)$site) == paste(model@frame$site[j], model@frame$Cluster[j], sep=":"), ]
}
B <- as.matrix(fixed[c("Neighbor_larger_log")])
X <- as.matrix(mod_matrix[, c("Neighbor_larger_log")])
part_resids <- resids + t(B) %*% t(X) + fixed["(Intercept)"] + ranefs
NL <- mod_matrix[, "Neighbor_larger_log"]
NL_back_trans <- (exp((NL * Neighbor_larger_sd) + Neighbor_larger_mean))
return(cbind(t(part_resids), NL_back_trans))
}
i <- 1
for(i in 1:3){
values = c(0.1,0.5,0.9)
# Use the function to get all the stuff we need (predictions, partial residuals, and SEs)
pred <- calculate_preds_Neighbor_larger(values[i])
#part_resids <- calculate_partial_residuals_NL(values[i])
plot(NA,
ylim = c(-25, 10),
xlim = c(min(pred$Neighbor_larger_natural_scale), max(pred$Neighbor_larger_natural_scale)),
xlab = "",
ylab = "",
log = "x",
cex.lab = 1.5,
xaxt = "n",
yaxt = "n"
)
#points(part_resids[, 1] ~ part_resids[, 2], pch = 21, col = "grey70", cex = 0.5)
lines(pred$predictions ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 2)
lines((pred$lo) ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 1.3)
lines((pred$hi) ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 1.3)
polygon(c(I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), rev(I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)))), c((pred$hi), rev((pred$lo))),
col = addTrans("grey",30), border = NA) #fills in the area between high and low confidence intervals
axis(1, at=c(0.001,.1, 10), labels = c(.001, .1, 10))
text(x = 0.9, y = -3, labels = paste0(values[i]*100, "% ENN Distance = \n",
round(exp((unname(quantile(all_tree_vars$ENN_dist, values[i])) * ENN_dist_sd + ENN_dist_mean)), 1), " m"),
cex = 0.7)
if(i == 1){
mtext(side = 3, at = 0.003, text= "(b)")
axis(2)
mtext(side = 2, text = "Predicted Change in Canopy (%)", cex = 0.7, outer = FALSE, line = 1.7)}
#label x axis
if(i == 2){mtext(side = 1, text = "Neighbor Size Ratio (log)", cex= 0.7, outer = FALSE, line = 2)}
}
dev.off()
#open device
tiff(filename="./plots/Figure 2 interaction plots.tif",
type="cairo",
units="in",
width = 6,
height = 6,
pointsize=15,
res=600,
compression = "lzw")
layout(matrix(c(1,2,3,4,5,6), nrow=2, ncol=3, byrow = TRUE))
par(mar = c(3,.5,1.2,0), oma = c(2,4,1,1), family = "serif", bty = 'n',
cex = 0.7, cex.lab = 0.7, cex.axis = 0.7)
#############################################################
### Pimo part -- figure 4a
#############################################################
model <- readRDS("./model output/pimo_model.rds")
#
# num_tree <- (nrow(all_tree_vars[all_tree_vars$Spp == "PIMO", ]))
# ranefs <- vector(mode = "numeric", length = num_tree)
###BA_4meter
calculate_preds_BA_4m <- function(quant){
#set all terms = 0, which is their mean value because all variables are standardized
C <- data.frame(matrix(ncol = length(names(coef(model)$Cluster)), nrow = 1000))
C <- as.data.frame(apply(C, c(1,2), FUN = function(x){return(0)}))
names(C) <- names(coef(model)$Cluster)
C$"(Intercept)" <- 1
C$cwd_normal_cum <- unname(quantile(all_tree_vars$cwd_normal_cum, quant))
#min value calculated to correspond to a real BA of -.001
C$BA_4m_log <- seq(-1.068, max(subset(all_tree_vars, select = "BA_4m_log")), length.out = 1000)
C$"cwd_normal_cum:BA_4m_log" = C$cwd_normal_cum * C$BA_4m_log
se <- vector(mode='numeric', length=nrow(C))
for (i in 1:nrow(C)){
se[i] <- as.numeric(calc.se(C[i, ]))
}
preds <- data.frame(
predictions = as.matrix(C) %*% as.matrix(fixef(model)),
lo = as.matrix(C) %*% as.matrix(fixef(model)) - 1.96*se,
hi = as.matrix(C) %*% as.matrix(fixef(model)) + 1.96*se,
# BA_4m = model@frame$`BA_4m`,
BA_4m_sim = C$BA_4m_log,
BA_4m_sim_natural_scale = (exp((C$BA_4m_log * BA_4m_sd) + BA_4m_mean)/10000) # in m2
)
return(preds)
}
calculate_partial_residuals_BA_4m <- function(quant){
model_frame <- model@frame
resids <- resid(model)
mod_matrix <- model.matrix(model)
fixed <- fixef(model)
if(quant == 0.1){
cwd_low <-  unname(quantile(all_tree_vars$cwd_normal_cum, 0))
cwd_high <-  unname(quantile(all_tree_vars$cwd_normal_cum, .30))
}
if(quant == 0.5){
cwd_low <-  unname(quantile(all_tree_vars$cwd_normal_cum, 0.3))
cwd_high <-  unname(quantile(all_tree_vars$cwd_normal_cum, .7))
}
if(quant == 0.9){
cwd_low <-  unname(quantile(all_tree_vars$cwd_normal_cum, 0.7))
cwd_high <-  unname(quantile(all_tree_vars$cwd_normal_cum, 1))
}
select_data <- which(model_frame$cwd_normal_cum > cwd_low & model_frame$cwd_normal_cum < cwd_high)
model_frame <- as.data.frame(model_frame[select_data, ])
resids <- resids[select_data]
mod_matrix <- mod_matrix[select_data, ]
ranefs <- vector(mode = "numeric", length = length(select_data))
for (i in (1:length(select_data))){
j <- select_data[i]
ranefs[i] <- ranef(model)$site[rownames(ranef(model)$site) == paste(model@frame$site[j], model@frame$Cluster[j], sep=":"), ]
}
B <- as.matrix(fixed[c("BA_4m_log")])
X <- as.matrix(mod_matrix[, c("BA_4m_log")])
part_resids <- resids + t(B) %*% t(X) + fixed["(Intercept)"] + ranefs
BA_4m <- mod_matrix[, "BA_4m_log"]
BA_4m_back_trans <- (exp((BA_4m * BA_4m_sd) + BA_4m_mean)/10000)
return(cbind(t(part_resids), BA_4m_back_trans))
}
for(i in 1:3){
values = c(0.1,0.5,0.9)
# Use the function to get all the stuff we need (predictions, partial residuals, and SEs)
pred <- calculate_preds_BA_4m(values[i])
#part_resids <- calculate_partial_residuals_BA_4m(values[i])
plot(NA,
ylim = c(-50, 10),
xlim = c(0.001, 3),
xlab = "",
ylab = "",
log = "x",
cex.lab = 1.5,
xaxt = "n",
yaxt = "n"
)
#points(part_resids[, 1] ~ part_resids[, 2], pch = 21, col = "grey70", cex = 0.5)
lines(pred$predictions ~ pred$BA_4m_sim_natural_scale, lwd = 2)
lines((pred$lo) ~ pred$BA_4m_sim_natural_scale, lwd = 1.3)
lines((pred$hi) ~ pred$BA_4m_sim_natural_scale, lwd = 1.3)
polygon(c(pred$BA_4m_sim_natural_scale, rev(pred$BA_4m_sim_natural_scale)), c((pred$hi), rev((pred$lo))),
col = addTrans("grey",30), border = NA) #fills in the area between high and low confidence intervals
text(x = 0.05, y = 5, labels = paste0(values[i]*100, "% CWD = \n",
round(((unname(quantile(all_tree_vars$cwd_normal_cum, values[i])) * cwd_normal_cum_sd + cwd_normal_cum_mean)), 0), " mm"),
cex = 0.7)
axis(1, at=c(0.001, 0.01, .1, 1))
if(i == 1){
mtext(side = 3, at = 0.003, text= "(a)")
axis(2)
mtext(side = 2, text = "Predicted Change in Canopy (%)", cex = 0.7, outer = FALSE, line = 1.7)}
#label x axis
if(i == 2){mtext(side = 1, text = expression(paste("BA, 4m buffer (", m^2, ")")), cex= 0.7, outer = FALSE, line = 2)}
}
#######################################################
### juos part -- figure 4b
#######################################################
model <- readRDS("./model output/juos_model.rds")
###BA_4meter
calculate_preds_Neighbor_larger <- function(quant){
#set all terms = 0, which is their mean value because all variables are standardized
C <- data.frame(matrix(ncol = length(names(coef(model)$Cluster)), nrow = 1000))
C <- as.data.frame(apply(C, c(1,2), FUN = function(x){return(0)}))
names(C) <- names(coef(model)$Cluster)
C$"(Intercept)" <- 1
C$ENN_dist_log <- unname(quantile(all_tree_vars$ENN_dist_log, quant))
#min value calculated to correspond to a real BA of -.001
C$Neighbor_larger_log <- minmax.sequence(all_tree_vars, "Neighbor_larger_log", 1000)
C$`ENN_dist_log:Neighbor_larger_log` = C$ENN_dist_log * C$Neighbor_larger_log
se <- vector(mode='numeric', length=nrow(C))
for (i in 1:nrow(C)){
se[i] <- as.numeric(calc.se(C[i, ]))
}
preds <- data.frame(
predictions = as.matrix(C) %*% as.matrix(fixef(model)),
lo = as.matrix(C) %*% as.matrix(fixef(model)) - 1.96*se,
hi = as.matrix(C) %*% as.matrix(fixef(model)) + 1.96*se,
# BA_4m = model@frame$`BA_4m`,
Neighbor_larger_sim = C$Neighbor_larger_log,
Neighbor_larger_natural_scale = (exp((C$Neighbor_larger_log * Neighbor_larger_sd) + Neighbor_larger_mean))
)
return(preds)
}
calculate_partial_residuals_NL <- function(quant){
model_frame <- model@frame
resids <- resid(model)
mod_matrix <- model.matrix(model)
fixed <- fixef(model)
if(quant == 0.1){
enn_low <-  unname(quantile(all_tree_vars$ENN_dist_log, 0))
enn_high <-  unname(quantile(all_tree_vars$ENN_dist_log, .30))
}
if(quant == 0.5){
enn_low <-  unname(quantile(all_tree_vars$ENN_dist_log, 0.3))
enn_high <-  unname(quantile(all_tree_vars$ENN_dist_log, .7))
}
if(quant == 0.9){
enn_low <-  unname(quantile(all_tree_vars$ENN_dist_log, 0.7))
enn_high <-  unname(quantile(all_tree_vars$ENN_dist_log, 1))
}
select_data <- which(model_frame$ENN_dist_log > enn_low & model_frame$ENN_dist_log < enn_high)
model_frame <- as.data.frame(model_frame[select_data, ])
resids <- resids[select_data]
mod_matrix <- mod_matrix[select_data, ]
ranefs <- vector(mode = "numeric", length = length(select_data))
for (i in (1:length(select_data))){
j <- select_data[i]
ranefs[i] <- ranef(model)$site[rownames(ranef(model)$site) == paste(model@frame$site[j], model@frame$Cluster[j], sep=":"), ]
}
B <- as.matrix(fixed[c("Neighbor_larger_log")])
X <- as.matrix(mod_matrix[, c("Neighbor_larger_log")])
part_resids <- resids + t(B) %*% t(X) + fixed["(Intercept)"] + ranefs
NL <- mod_matrix[, "Neighbor_larger_log"]
NL_back_trans <- (exp((NL * Neighbor_larger_sd) + Neighbor_larger_mean))
return(cbind(t(part_resids), NL_back_trans))
}
i <- 1
for(i in 1:3){
values = c(0.1,0.5,0.9)
# Use the function to get all the stuff we need (predictions, partial residuals, and SEs)
pred <- calculate_preds_Neighbor_larger(values[i])
#part_resids <- calculate_partial_residuals_NL(values[i])
plot(NA,
ylim = c(-25, 10),
xlim = c(min(pred$Neighbor_larger_natural_scale), max(pred$Neighbor_larger_natural_scale)),
xlab = "",
ylab = "",
log = "x",
cex.lab = 1.5,
xaxt = "n",
yaxt = "n"
)
#points(part_resids[, 1] ~ part_resids[, 2], pch = 21, col = "grey70", cex = 0.5)
lines(pred$predictions ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 2)
lines((pred$lo) ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 1.3)
lines((pred$hi) ~ I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), lwd = 1.3)
polygon(c(I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)), rev(I(exp((pred$Neighbor_larger_sim * Neighbor_larger_sd) + Neighbor_larger_mean)))), c((pred$hi), rev((pred$lo))),
col = addTrans("grey",30), border = NA) #fills in the area between high and low confidence intervals
axis(1, at=c(0.001,.1, 10), labels = c(.001, .1, 10))
text(x = 0.9, y = 5, labels = paste0(values[i]*100, "% ENN Distance = \n",
round(exp((unname(quantile(all_tree_vars$ENN_dist, values[i])) * ENN_dist_sd + ENN_dist_mean)), 1), " m"),
cex = 0.7)
if(i == 1){
mtext(side = 3, at = 0.003, text= "(b)")
axis(2)
mtext(side = 2, text = "Predicted Change in Canopy (%)", cex = 0.7, outer = FALSE, line = 1.7)}
#label x axis
if(i == 2){mtext(side = 1, text = "Neighbor Size Ratio (log)", cex= 0.7, outer = FALSE, line = 2)}
}
dev.off()
plot_vars
View(alldata)
View(alldata)
View(alldata_unscaled)
exp(-1.15)
exp(1.15)
exp(-1.2)
exp(-.52)
exp(.78)
exp(.37)
exp(.96)
1/.3
exp(1.2)
exp(.52)
exp(1.1507)
exp(1.1597)
exp(.703)
exp(1.168)
exp(-.686)
exp(-.961)
exp(-.252)
exp(.79)
ex[(/28)]
exp(1.14)
exp(.28)
exp(.7944)
exp(.352)
exp(.001)
exp(.58)
#global model with tree-level vars and abiotic vars
pimo_global <- lmer(formula = Delta_pdc ~ Neighbor_larger_log + ENN_dist_log + Diam_log + Height + BA_4m_log +
cwd_normal_cum + fdsi_anom +
cwd_peak_anom + tmean + ppt +
vpd_normal_annual_max + vpd_peak_anom + avg_summer_tmax +
peak_tmax + min_ann_ppt +
Pndjfm + Avg_depth + AWC +
(1|Cluster/site),
data = all_tree_vars[all_tree_vars$Spp == "PIMO", ],
na.action = na.fail)
#only use combos that aren't pairwise correlated
cormat <- abs(cor(all_tree_vars[all_tree_vars$Spp == "PIMO", c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log',
'cwd_normal_cum', 'fdsi_anom',
'cwd_peak_anom' , 'tmean', 'ppt',
'vpd_normal_annual_max' , 'vpd_peak_anom' , 'avg_summer_tmax', 'peak_tmax',
'min_ann_ppt',  'Pndjfm' , 'Avg_depth' , 'AWC')])) <=.5
#use all tree-level vars
cormat[1:5,1:5] <- TRUE
#use only one side of matrix (avoid duplicated models)
cormat[!lower.tri(cormat)] <- NA
#find all combinations with a few given conditions:
# abiotic variables can change but stand structure variables are fixed;
# abiotic variables with correlations greater than .5 are not allowed;
# 9 maximum variables are allowed;
# progress is displayed in console
# this only takes a minute or two
pimo_dredge <- dredge(pimo_global,
fixed = c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log'),
subset = cormat,
m.lim = c(5, 8),
trace = 2)
saveRDS(pimo_dredge, "./model output/pimo_dredge.RDS")
#get call for top model and evaluate it
best_pimo_call <- as.character(unlist(attr((pimo_dredge)[1], "model.calls")))
pimo_model_dredge <- eval(parse(text = best_pimo_call))
summary(pimo_model_dredge)
pimo_dredge[1:10] #top 10 models
#### Analysis of field data
# Sam Flake, 12 Sep 2017
# sflake@gmail.com or swflake@ncsu.edu
# load libraries
library(plyr)
library(boot)
library(lme4)
library(MuMIn)
library(car)
library(effects)
library(pscl)
library("pROC")
## set up some options
set.seed(665224291)
options(na.action = na.fail)
pardefault <- par(no.readonly = T)
#Source some useful functions
source("pj_mortality_functions_090617.R")
#read prepared data
all_tree_vars <- read.csv("./Clean data/all_tree_Vars_scaled_and_transformed.csv")
all_tree_vars_orig <- read.csv("./Clean data/all_tree_Vars_unscaled_untrans.csv")
#--------------------------------------------------------------------------------------------
# tree-level models
#global model with tree-level vars and abiotic vars
pimo_global <- lmer(formula = Delta_pdc ~ Neighbor_larger_log + ENN_dist_log + Diam_log + Height + BA_4m_log +
cwd_normal_cum + fdsi_anom +
cwd_peak_anom + tmean + ppt +
vpd_normal_annual_max + vpd_peak_anom + avg_summer_tmax +
peak_tmax + min_ann_ppt +
Pndjfm + Avg_depth + AWC +
(1|Cluster/site),
data = all_tree_vars[all_tree_vars$Spp == "PIMO", ],
na.action = na.fail)
#only use combos that aren't pairwise correlated
cormat <- abs(cor(all_tree_vars[all_tree_vars$Spp == "PIMO", c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log',
'cwd_normal_cum', 'fdsi_anom',
'cwd_peak_anom' , 'tmean', 'ppt',
'vpd_normal_annual_max' , 'vpd_peak_anom' , 'avg_summer_tmax', 'peak_tmax',
'min_ann_ppt',  'Pndjfm' , 'Avg_depth' , 'AWC')])) <=.5
#use all tree-level vars
cormat[1:5,1:5] <- TRUE
#use only one side of matrix (avoid duplicated models)
cormat[!lower.tri(cormat)] <- NA
#find all combinations with a few given conditions:
# abiotic variables can change but stand structure variables are fixed;
# abiotic variables with correlations greater than .5 are not allowed;
# 9 maximum variables are allowed;
# progress is displayed in console
# this only takes a minute or two
pimo_dredge <- dredge(pimo_global,
fixed = c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log'),
subset = cormat,
m.lim = c(5, 8),
trace = 2)
saveRDS(pimo_dredge, "./model output/pimo_dredge.RDS")
#get call for top model and evaluate it
best_pimo_call <- as.character(unlist(attr((pimo_dredge)[1], "model.calls")))
pimo_model_dredge <- eval(parse(text = best_pimo_call))
summary(pimo_model_dredge)
pimo_dredge[1:10] #top 10 models
write.csv(pimo_dredge[1:10], "./model output/pimo_mod_selection_table.csv")
#global model with tree-level vars and abiotic vars
juos_global <- lmer(formula = Delta_pdc ~ Neighbor_larger_log + ENN_dist_log + Diam_log + Height + BA_4m_log +
cwd_normal_cum + fdsi_anom +
cwd_peak_anom + tmean + ppt +
vpd_normal_annual_max + vpd_peak_anom + avg_summer_tmax +
peak_tmax + min_ann_ppt +
Pndjfm + Avg_depth + AWC +
(1|Cluster/site),
data = all_tree_vars[all_tree_vars$Spp == "JUOS", ],
na.action = na.fail)
#only use combos that aren't pairwise correlated
cormat <- abs(cor(all_tree_vars[all_tree_vars$Spp == "JUOS", c('Neighbor_larger_log', 'ENN_dist_log', 'Height', 'Diam_log', 'BA_4m_log',
'cwd_normal_cum', 'fdsi_anom',
'cwd_peak_anom' , 'tmean', 'ppt',
'vpd_normal_annual_max' , 'vpd_peak_anom' , 'avg_summer_tmax', 'peak_tmax',
'min_ann_ppt',  'Pndjfm' , 'Avg_depth' , 'AWC')])) <=.5
#use all tree-level vars
cormat[1:5,1:5] <- TRUE
#use only one side of matrix (avoid duplicated models)
cormat[!lower.tri(cormat)] <- NA
#find all combinations
juos_dredge <- dredge(juos_global,
fixed = c('Neighbor_larger_log', 'ENN_dist_log', 'Height', 'Diam_log', 'BA_4m_log'),
subset = cormat,
m.lim = c(5, 8),
trace = 2)
saveRDS(juos_dredge, "./model output/juos_dredge.RDS")
#get call for top model and evaluate it
best_juos_call <- as.character(unlist(attr((juos_dredge)[1], "model.calls")))
juos_model_dredge <- eval(parse(text = best_juos_call))
write.csv(juos_dredge[1:10], "./model output/juos_mod_selection_table.csv")
# ###################################
# # PIMO mortality
# ###################################
pmort_global <- glmer(formula = Died ~ Neighbor_larger_log + ENN_dist_log + Diam_log + Height + BA_4m_log +
cwd_normal_cum + fdsi_anom +
cwd_peak_anom + tmean + ppt +
vpd_normal_annual_max + vpd_peak_anom + avg_summer_tmax +
peak_tmax + min_ann_ppt +
Pndjfm + Avg_depth + AWC +
(1|site), family = "binomial",
data = all_tree_vars[all_tree_vars$Spp == "PIMO", ], na.action = na.fail)
#only use combos that aren't pairwise correlated
cormat <- abs(cor(all_tree_vars[all_tree_vars$Spp == "PIMO", c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log',
'cwd_normal_cum', 'fdsi_anom',
'cwd_peak_anom' , 'tmean', 'ppt',
'vpd_normal_annual_max' , 'vpd_peak_anom' , 'avg_summer_tmax', 'peak_tmax',
'min_ann_ppt',  'Pndjfm' , 'Avg_depth' , 'AWC')])) <=.5
#use all tree-level vars
cormat[1:5,1:5] <- TRUE
#use only one side of matrix (avoid duplicated models)
cormat[!lower.tri(cormat)] <- NA
# find all combinations with a few given conditions:
# abiotic variables can change but stand structure variables are fixed;
# abiotic variables with correlations greater than .5 are not allowed;
# 8 maximum variables are allowed;
# progress is displayed in console
# this only takes a half an hour or so
start.time <- Sys.time()
pmort_dredge <- dredge(pmort_global,
fixed = c('Neighbor_larger_log', 'ENN_dist_log', 'Diam_log', 'Height', 'BA_4m_log'),
subset = cormat,
m.lim = c(5, 8),
trace = 2)
end.time <- Sys.time()
time.taken_pmort_dredge <- end.time - start.time
time.taken_pmort_dredge #30 minutes
saveRDS(pmort_dredge, "./model output/pmort_dredge.RDS")
(pmort_dredge)[c(1:10)]
#get call for top model and evaluate it
best_pmort_call <- as.character(unlist(attr((pmort_dredge)[1], "model.calls")))
pmort_model_dredge <- eval(parse(text = best_pmort_call))
write.csv(pmort_dredge[1:10], "./model output/pmort_mod_selection_table.csv")
#### Analysis of field data
library(plyr)
library(lme4)
library(MuMIn)
library(boot)
library(car)
source("pj_mortality_functions_090617.R")
options(na.action = na.fail)
plot_data <- read.csv("./Clean data/plot_level_vars.csv")
plot_data_scaled <- read.csv("./Clean data/plot_level_vars_scaled.csv")
#---------------------------------------------------------------------------------
####################### Plot analysis
###### Select climate variables
######################################
#global model with all abiotic variables
plot_climate_global <- lmer(Avg_delta_pdc ~ avg_height +
avg_Diam + avg_ENN + BA.Plot + Pct_pimo +
cwd_normal_cum + fdsi_anom +
cwd_peak_anom + tmean + ppt +
vpd_normal_annual_max + vpd_peak_anom + avg_summer_tmax +
peak_tmax + min_ann_ppt +
Pndjfm + Avg_depth + AWC + (1|Cluster), data = plot_data_scaled, na.action = na.fail)
#correlation matrix to select only variables pairwise correlated with r <=0.5
cormat <- abs(cor(plot_data_scaled[, c('avg_height',
'avg_Diam', 'avg_ENN', 'BA.Plot', 'Pct_pimo',
'cwd_normal_cum', 'fdsi_anom',
'cwd_peak_anom' , 'tmean', 'ppt',
'vpd_normal_annual_max' , 'vpd_peak_anom' , 'avg_summer_tmax', 'peak_tmax',
'min_ann_ppt',  'Pndjfm' , 'Avg_depth' , 'AWC')])) <=.5
#use all stand structure vars
cormat[1:5,1:5] <- TRUE
#use only one side of matrix (avoid duplicated models)
cormat[!lower.tri(cormat)] <- NA
# build models with all combinations of abiotic variables, with a maximum of 4 variables per model
# this is very quick (a few seconds)
plot_dredge <- dredge(plot_climate_global,
fixed = c('avg_height','avg_Diam', 'avg_ENN',
'BA.Plot', 'Pct_pimo'),
subset = cormat,
m.lim = c(5, 8),
trace = 2)
saveRDS(plot_dredge, "./model output/plot_dredge_outputs.rds")
best_plot_call <- as.character(unlist(attr((plot_dredge)[1], "model.calls")))
plot_model_dredge <- eval(parse(text = best_plot_call))
summary(plot_model_dredge)
r.squaredGLMM(plot_model_dredge)
summary(plot_model_dredge)
AICc(plot_model_dredge)
plot_dredge[1:10] #top 10 models
write.csv(plot_dredge[1:10], "plot_level_mod_selection_table.csv")
write.csv(plot_dredge[1:10], "./model output/plot_level_mod_selection_table.csv")
